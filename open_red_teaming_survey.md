
## Our Survey: Against The Achillesâ€™ Heel: A Survey on Red Teaming for Generative Models [[Paper](https://arxiv.org/abs/2404.00629)]
To gain a comprehensive understanding of potential attacks on GenAI and develop robust safeguards. We:
* Survey over 120 papers, cover the pipeline from risk taxonomy, attack strategies, evaluation metrics, and benchmarks to defensive approaches.
* propose a comprehensive taxonomy of LLM attack strategies grounded in the inherent capabilities of models developed during pretraining and fine-tuning.
* Implemented more than 30+ auto red teaming methods. (Which will not be open-sourced to avoid malicious use.)
* Please review the [complete list of papers](/paper_list/README.md) for the latest research.

To stay updated or try our RedTeaming tool, please subscribe to our newsletter at [our website](https://www.librai.tech/) or join us on [Discord](https://discord.gg/3Yxgth5E)!



#### Red teaming Papers by type from 2023 onwards.
<p align="center"> <img src="assets/papers.png" style="width: 80%;" id="title-icon">       </p>

#### Overview
<p align="center"> <img src="assets/overview.png" style="width: 80%;" id="title-icon">       </p>

#### Language Model Attack Strategy, Prompt Searcher, and Defense

<p align="center"> <img src="assets/strategy.png" style="width: 80%;" id="title-icon">       </p>
<p align="center"> <img src="assets/seacher.png" style="width: 80%;" id="title-icon">       </p>

### Benchmarks, Multimodal Red Teaming, Agent Red Teaming

To know more about these, please read our [paper](https://arxiv.org/abs/2404.00629).



### Citation
```
@article{lin2024achilles,
      title={Against The Achilles' Heel: A Survey on Red Teaming for Generative Models}, 
      author={Lizhi Lin and Honglin Mu and Zenan Zhai and Minghan Wang and Yuxia Wang and Renxi Wang and Junjie Gao and Yixuan Zhang and Wanxiang Che and Timothy Baldwin and Xudong Han and Haonan Li},
      year={2024},
      journal={arXiv preprint, arXiv:2404.00629},
      primaryClass={cs.CL}
}
```
